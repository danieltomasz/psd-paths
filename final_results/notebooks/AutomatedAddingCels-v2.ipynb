{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Adding cell content to a Jupyter notebook\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Define kernel metadata, add YAML and add imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbformat.validator import ValidationError\n",
    "import re\n",
    "\n",
    "\n",
    "def validate_and_repair_notebook(notebook_path):  # type: ignore\n",
    "    # Read the notebook\n",
    "    with open(notebook_path, \"r\") as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    # Validate the notebook\n",
    "    try:\n",
    "        nbformat.validate(nb)\n",
    "        print(\"The notebook is valid.\")\n",
    "    except ValidationError as e:\n",
    "        print(\"The notebook is not valid:\", e)\n",
    "\n",
    "        # If the notebook is not valid, try to repair it\n",
    "        nb = nbformat.reads(nbformat.writes(nb), as_version=4)\n",
    "        with open(notebook_path, \"w\") as f:\n",
    "            nbformat.write(nb, f)\n",
    "        print(\"The notebook has been repaired.\")\n",
    "\n",
    "\n",
    "def add_kernel_metadata(nb):\n",
    "    nb[\"metadata\"][\"kernelspec\"] = {\n",
    "        \"display_name\": \"Python 3\",\n",
    "        \"language\": \"python\",\n",
    "        \"name\": \"conda-paths-3.12\",\n",
    "    }\n",
    "\n",
    "\n",
    "def add_yaml_metadata(nb):\n",
    "    raw_cell_content = \"\"\"---\n",
    "title: \"Preprocessing of High-Density EEG Recordings\"\n",
    "execute:\n",
    "    echo: false\n",
    "    warning: false\n",
    "    enabled: true\n",
    "format:\n",
    "    html:\n",
    "        page-layout: full\n",
    "        toc: true\n",
    "        toc-location: left\n",
    "        embed-resources: true\n",
    "---\"\"\"\n",
    "    nb[\"cells\"] += [nbformat.v4.new_raw_cell(raw_cell_content)]\n",
    "\n",
    "\n",
    "def add_import_cells(nb, backend=\"matplotlib\"):\n",
    "    functions_cell = \"\"\"import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing import ICA\n",
    "from mne_icalabel.gui import label_ica_components\n",
    "import autoreject\n",
    "from specparam.plts.spectra import plot_spectra\n",
    "from specparam import SpectralGroupModel\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "from utils import (\n",
    "    compare_before_after,\n",
    "    create_epochs,\n",
    "    switch_bad_to_interpolate,\n",
    "    update_reject_log,\n",
    "    plot_specparam_on_scalp,\n",
    "    examine_spectra,\n",
    "    exclude_bad_channels,\n",
    "    extract_elements,\n",
    "    save_specparam_results,\n",
    "    plot_models\n",
    ")\n",
    "plt.close(\"all\")\n",
    "\n",
    "# mne.viz.set_browser_backend(\"matplotlib\") # As an alternative, you can use \"qt\" for the Qt backend\n",
    "mne.set_config(\"MNE_BROWSER_BACKEND\", \"{backend}\")\n",
    "\n",
    "\n",
    "auto_reject_params = {{\n",
    "    \"n_interpolate\": [1, 2, 16, 32],\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": 100,\n",
    "    \"thresh_method\": \"bayesian_optimization\",\n",
    "    \"verbose\": False,\n",
    "    \"consensus\": [0.8],\n",
    "}}\n",
    "\n",
    "auto_reject_pre_ica = autoreject.AutoReject(**auto_reject_params)\n",
    "\n",
    "fmax = 40.0\n",
    "fg = SpectralGroupModel(\n",
    "    peak_width_limits=[1, 6],\n",
    "    min_peak_height=0.15,\n",
    "    peak_threshold=2.0,\n",
    "    max_n_peaks=6,\n",
    "    verbose=False,\n",
    ")\n",
    "recompute = False\n",
    "\n",
    "\"\"\"\n",
    "    nb[\"cells\"] += [nbformat.v4.new_markdown_cell(\"## Import libraries\")]\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(functions_cell.format(backend=backend))]\n",
    "\n",
    "\n",
    "def import_epochs(nb, sub_id: int):\n",
    "    code_raw_data = \"\"\"# import raw data or epochs\n",
    "subject = {sub_id}\n",
    "auto_reject_params = {{\n",
    "    \"n_interpolate\": [\n",
    "        1,\n",
    "        2,\n",
    "    ],\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": 100,\n",
    "    \"thresh_method\": \"bayesian_optimization\",\n",
    "    \"verbose\": False,\n",
    "    \"consensus\": [0.4],\n",
    "}}\n",
    "#epochs_params = {{\"reject\": dict(eeg=400e-6)}}\n",
    "# Check if the file exists\n",
    "\n",
    "df = pd.read_excel(\"ICA TO REMOVE.xlsx\")\n",
    "\n",
    "channels_to_add = [\"E\" + str(ch) for ch in extract_elements(df, {sub_id}, \"Bad_Channels\")]\n",
    "print(channels_to_add)\n",
    "raw = mne.io.read_raw_fif(f\"sub-{{subject}}_filtered_raw.fif\", preload=True).filter(\n",
    "    l_freq=1.0, h_freq=None\n",
    ")\n",
    "for channel in channels_to_add:\n",
    "    raw.info[\"bads\"].append(channel)\n",
    "\n",
    "raw.plot()\n",
    "\n",
    "epochs = create_epochs(raw, epochs_params=None, length=5, overlap=1.5)\n",
    "\n",
    "autoreject_fname = f\"sub-{{subject}}_auto_reject_pre_ica.h5\"\n",
    "if os.path.exists(autoreject_fname) and recompute is False:\n",
    "    auto_reject_pre_ica = autoreject.read_auto_reject(autoreject_fname)\n",
    "    print(f\"File {{autoreject_fname}} exists. Loading file\")\n",
    "else:\n",
    "    print(f\"File {{autoreject_fname}} does not exist.\")\n",
    "    auto_reject_pre_ica = autoreject.AutoReject(**auto_reject_params).fit(epochs[:20])\n",
    "    print(\"fitting finished\")\n",
    "    auto_reject_pre_ica.save(autoreject_fname, overwrite=True)\n",
    "    print(f\"File {{autoreject_fname}} saved\")\n",
    "\n",
    "epochs_ar, reject_log = auto_reject_pre_ica.transform(epochs, return_log=True)\n",
    "reject_plot = reject_log.plot(\"vertical\")\"\"\"\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(code_raw_data.format(sub_id=sub_id))]\n",
    "\n",
    "\n",
    "def rejection_log_manipulation(nb, sub_id: int):\n",
    "    code_raw_data1 = \"\"\"scalings = dict(eeg=60e-6)\n",
    "\n",
    "df = pd.read_excel(\"ICA TO REMOVE.xlsx\")\n",
    "bad_epochs_indices = extract_elements(df, {sub_id}, \"Epochs\")\n",
    "\n",
    "if len(bad_epochs_indices) > 0:\n",
    "    zeroed_reject_log = switch_bad_to_interpolate(reject_log)\n",
    "    new_reject_log = update_reject_log(zeroed_reject_log, bad_epochs_indices)\n",
    "else:\n",
    "    new_reject_log = reject_log\n",
    "new_reject_log.save(f\"sub-{{subject}}_reject_log_updated.h5\", overwrite=True)\"\"\"\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(code_raw_data1.format(sub_id=sub_id))]\n",
    "\n",
    "    code_raw_data2 = \"\"\"# plot bad epochs if exists\n",
    "new_reject_log.plot_epochs(epochs, scalings=scalings)\n",
    "epochs[new_reject_log.bad_epochs].plot(scalings=scalings)\n",
    "epochs[~new_reject_log.bad_epochs].plot(scalings=scalings)\"\"\"\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(code_raw_data2.format(sub_id=sub_id))]\n",
    "\n",
    "\n",
    "def compute_ica(nb, sub_id: int):\n",
    "    code_raw_data = \"\"\"# Compute ICA\n",
    "ica_params = {{\n",
    "    \"n_components\": 0.99,\n",
    "    \"random_state\": 99,\n",
    "    \"method\": \"picard\",\n",
    "    \"fit_params\": {{\"ortho\": False, \"extended\": True}},\n",
    "}}\n",
    "\n",
    "ica = ICA(**ica_params)\n",
    "new_epochs = epochs[~new_reject_log.bad_epochs]\n",
    "\n",
    "ica.fit(new_epochs)\n",
    "if ica.n_components_ > 50:\n",
    "    ica_params = {{\n",
    "        \"n_components\": 50,\n",
    "        \"random_state\": 99,\n",
    "        \"method\": \"picard\",\n",
    "        \"fit_params\": {{\"ortho\": False, \"extended\": True}},\n",
    "    }}\n",
    "    ica = ICA(**ica_params)\n",
    "    ica.fit(new_epochs)\"\"\"\n",
    "    code_component_ica = \"\"\"# Plot bad components\n",
    "# plot  ica with bad components\n",
    "df = pd.read_excel(\"ICA TO REMOVE.xlsx\")\n",
    "ica_bad_components = extract_elements(df, {sub_id}, \"ICA_3Take\")\n",
    "print(ica_bad_components)\n",
    "# quick  comparison\n",
    "ica.exclude =  ica_bad_components\n",
    "_ = ica.plot_components()\"\"\"\n",
    "    nb[\"cells\"] += [nbformat.v4.new_markdown_cell(\"## ICA\")]\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(code_raw_data.format())]\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(code_component_ica.format(sub_id=sub_id))]\n",
    "\n",
    "\n",
    "def ica_bad_components(nb, sub_id: int):\n",
    "    code_raw_data = \"\"\"# Plot bad components\n",
    "# plot  ica with bad components\n",
    "if mne.get_config(\"MNE_BROWSER_BACKEND\") == \"qt\":\n",
    "    ica.exclude = ica_bad_components\n",
    "    ica_plot_whole_timeseries = ica.plot_sources(\n",
    "        new_epochs,\n",
    "        picks=None,\n",
    "        show_scrollbars=True,\n",
    "    )\n",
    "    gui = label_ica_components(new_epochs, ica)\n",
    "\n",
    "else:\n",
    "    ica.exclude = []\n",
    "    ica_plot_whole_timeseries = ica.plot_sources(\n",
    "        new_epochs,\n",
    "        picks=ica_bad_components,\n",
    "        show_scrollbars=False,\n",
    "        start=0,\n",
    "        stop=len(new_epochs) - 1,\n",
    "    )\"\"\"\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(code_raw_data.format(sub_id=sub_id))]\n",
    "\n",
    "\n",
    "def ica_compare_bad_and_cleaned_data(nb, sub_id: int):\n",
    "    code_raw_data = \"\"\"# Compare bad data\n",
    "ica.exclude = ica_bad_components\n",
    "ica.save(f'sub-{sub_id}_my_ica_model-ica.fif',  overwrite=True)\n",
    "epochs_clean_manual = ica.apply(new_epochs.copy(), exclude=ica.exclude)\n",
    "fig_psd = compare_before_after(\n",
    "    epochs[~new_reject_log.bad_epochs],\n",
    "    epochs_clean_manual,\n",
    "    subject,\n",
    ")\"\"\"\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(code_raw_data.format(sub_id=sub_id))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code chunks computed during iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add autoreject parts\n",
    "def add_autoreject_post_ica_cells(nb, sub_id: int):\n",
    "    autoreject_chunk = \"\"\"auto_reject_post_ica = autoreject.AutoReject(\n",
    "    n_interpolate=[1, 2, 4, 8, 32, 64],\n",
    "    n_jobs=-1,\n",
    "    random_state=100,\n",
    "    thresh_method=\"bayesian_optimization\",\n",
    "    verbose=False,\n",
    "    # n_interpolate=np.array([0]),\n",
    "    # consensus=0.8,\n",
    ").fit(epochs_clean_manual[:20])\n",
    "print(\"fitting finished\")\n",
    "epochs_ar, reject_log_final = auto_reject_post_ica.transform(\n",
    "    epochs_clean_manual, return_log=True\n",
    ")\n",
    "autoreject_post_fname = f\"sub-{{subject}}_auto_reject_post_ica.h5\"\n",
    "auto_reject_post_ica.save(autoreject_post_fname, overwrite=True)\n",
    "\n",
    "reject_plot = reject_log_final.plot(\"vertical\")\n",
    "reject_log_final.save(f\"sub-{{subject}}_reject_log_final.h5\", overwrite=True)\n",
    "\n",
    "epochs_interpolated = epochs_ar.copy().interpolate_bads(exclude=[\"VREF\"])\n",
    "epochs_interpolated.save(\n",
    "    f\"analysis/sub-{{subject}}_interpolated-epo.fif\", overwrite=True\n",
    ")\"\"\"\n",
    "\n",
    "    nb[\"cells\"] += [\n",
    "        nbformat.v4.new_markdown_cell(\n",
    "            \"## Extrapolation of bad channels using autoreject\"\n",
    "        )\n",
    "    ]\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(autoreject_chunk.format())]\n",
    "\n",
    "\n",
    "def add_comparison_cells(nb):\n",
    "    comparison_chunk = \"\"\"# plot comparison\n",
    "fig_psd1 = compare_before_after(epochs_clean_manual, epochs_interpolated, subject, title=\"After AR\")\"\"\"\n",
    "\n",
    "    nb[\"cells\"] += [nbformat.v4.new_markdown_cell(\"## Comparison of EEG data\")]\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(comparison_chunk)]\n",
    "\n",
    "\n",
    "# compute specparam\n",
    "def add_specparam_cells(nb, sub_id: int):\n",
    "    specparam_chunk = \"\"\"from utils import (\n",
    "    save_specparam_results,\n",
    "    plot_specparam_on_scalp,\n",
    "    examine_spectra,\n",
    "    plot_models,\n",
    ")\n",
    "subject = {sub_id}\n",
    "raw = mne.io.read_raw_fif(f\"sub-{{subject}}_filtered_raw.fif\", preload=True).filter(\n",
    "    l_freq=1.0, h_freq=None\n",
    ")\n",
    "n_interpolated_channels = len(raw.info[\"bads\"])\n",
    "# epochs = create_epochs(raw, epochs_params=None, length=5, overlap=1.5)\n",
    "epochs_interpolated = mne.read_epochs(\n",
    "    f\"analysis/sub-{{subject}}_interpolated-epo.fif\", preload=True\n",
    ")\n",
    "ica_loaded = mne.preprocessing.read_ica(f\"sub-{{subject}}_my_ica_model-ica.fif\")\n",
    "\n",
    "psd = epochs_interpolated.compute_psd().average()\n",
    "spectra, freqs = psd.get_data(return_freqs=True)\n",
    "# Initialize a FOOOFGroup object, with desired settings\n",
    "\n",
    "# Define the frequency range to fit\n",
    "freq_range = [2, 40]\n",
    "fg.fit(freqs, spectra, freq_range)\n",
    "fg.plot()\n",
    "specparam_df = save_specparam_results(\n",
    "    fg,\n",
    "    epochs_interpolated,\n",
    "    ica_loaded,\n",
    "    subject,\n",
    "    n_interpolated_channels=n_interpolated_channels,\n",
    ")\n",
    "display(specparam_df.head())\n",
    "#epochs_ar_good = exclude_bad_channels(epochs_interpolated)\n",
    "\n",
    "plot_specparam_on_scalp(fg,  epochs_interpolated, subject)\n",
    "examine_spectra(fg, subject)\n",
    "\"\"\"\n",
    "\n",
    "    plot_models1 = \"\"\"# plot models that are smallest, median and highest exponent\n",
    "plot_models(fg, param_choice=\"exponent\")\"\"\"\n",
    "\n",
    "    plot_models2 = \"\"\"# plot models with worst, median and best goodness of fit\n",
    "plot_models(fg, param_choice=\"r_squared\")\"\"\"\n",
    "\n",
    "    nb[\"cells\"] += [nbformat.v4.new_markdown_cell(\"## Specparam visualisation\")]\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(specparam_chunk.format(sub_id=sub_id))]\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(plot_models1.format())]\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(plot_models2.format())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n",
      "The notebook is valid.\n"
     ]
    }
   ],
   "source": [
    "numbers = [\n",
    "    101,\n",
    "    106,\n",
    "    108,\n",
    "    120,\n",
    "    124,\n",
    "    126,\n",
    "    128,\n",
    "    129,\n",
    "    132,\n",
    "    135,\n",
    "    139,\n",
    "    142,\n",
    "    144,\n",
    "    145,\n",
    "    146,\n",
    "    147,\n",
    "]\n",
    "\n",
    "for sub_id in numbers:\n",
    "    output_path = f\"../check_subjects/sub_{sub_id}_reanalysis.ipynb\"\n",
    "\n",
    "    # create notebook\n",
    "    nb = nbformat.v4.new_notebook()\n",
    "    add_kernel_metadata(nb)\n",
    "    add_yaml_metadata(nb)\n",
    "    add_import_cells(nb, backend=\"qt\")\n",
    "    nb[\"cells\"] += [nbformat.v4.new_markdown_cell(\"# Subject {}\".format(sub_id))]\n",
    "    # plot_raw_data(nb, sub_id)\n",
    "    import_epochs(nb, sub_id=sub_id)\n",
    "    rejection_log_manipulation(nb, sub_id=sub_id)\n",
    "    compute_ica(nb, sub_id=sub_id)\n",
    "    ica_bad_components(nb, sub_id=sub_id)\n",
    "    ica_compare_bad_and_cleaned_data(nb, sub_id=sub_id)\n",
    "    add_autoreject_post_ica_cells(nb, sub_id=sub_id)\n",
    "    add_comparison_cells(nb)\n",
    "    add_specparam_cells(nb, sub_id=sub_id)\n",
    "    nb[\"cells\"] += [nbformat.v4.new_code_cell(\"\"\"plt.close(\"all\")\"\"\".format())]\n",
    "    # write notebook\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        nbformat.write(nb, f)\n",
    "\n",
    "    # validate and repair notebook if needed\n",
    "    validate_and_repair_notebook(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-paths-3.12",
   "language": "python",
   "name": "conda-paths-3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
